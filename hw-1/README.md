### Модуль 1. Введение в сбор данных

В рамках выполнения задания реализованы 2 пакеты:
1. Веб-скраппер и парсер, написан на `nodejs`,
2. Анализатор данных, написан на `python`.

При реализации веб-скраппинга были использованы следующие техники:
1. Выгрузка данных с веб-сайта автоматическим методом.
2. Выгрузка данных и навигация по сайту с помощью headless браузера.
3. Выгрузка данных ручным способом.
4. Поиск данных в открытых источниках (kaggle).

Веб-скраппер может собрать следующие датасеты:
- датасет по ценам за GPU с сайта pcbuilder;
- датасет по спецификациям на GPU с сайта techpowerup;

Парсер может дополнительно распарсить следующие источники данных:
- страницы с бенчмарками с сайта tomshardware;
- страницы с оценками и ценами с сайта userbenchmark;
- страницы с ценами на комплектующие с сайта pcpartpicker.


При реализации анализатора данных изначально планировалось сделать утилиту, но в итоге анализ датасетов был реализован чисто в ноутбуке. 

В обзоре данных приведено их описание, структура, проведены преобразования для корректной агрегации. 

При анализе рассмотрены 3 кейса по использования данных для принятия решений и поиска информации. 
